---
title: "analysisLKP.Rmd"
author: "LK Pino"
date: "March 5, 2017"
output: html_document
---

Hi guys

I'm moving my \*.R code into \*.Rmd so that I can make comments for my write up, and because the code is getting a little long and I wanted to organize!

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache=TRUE)
options(digits = 3) ## Formats output to 3 digits
library(gtools)
library(ggplot2)
library(dplyr)
library(data.table)
library(reshape2)
#source("http://bioconductor.org/biocLite.R")  # for timecourse analysis
#biocLite("edge")  # for timecourse analysis
library(edge)  # for timecourse analysis
library(splines)
library(gridExtra)
library(glmnet)  # for lasso

dir <- getwd()
setwd(dir)
all.df <- read.csv("../data/prp_tendon_cleaned2_reshaped_delim_20170310.csv")  # data frame cleaned and 'normalized' in excel
```

I'm starting by just making some summary statistics and plots for the data, in order to get a feel for what I'm working with.

```{r summarystats_meta}
## Missingness by feature, ie how many N/As per column
apply(all.df, 2, function(x){sum(is.na(x))}) 
complete <- all.df %>% complete.cases()
mean(complete)  ## proportion of cases complete
length(unique(all.df$patientid))  ## total unique patients

## subset for metadata features
meta.df <- all.df %>% select(patientid, treatment, age, race, gender_num, duration_months)  # subset for features we'll be using 
apply(meta.df, 2, function(x){sum(is.na(x))}) 
complete <- meta.df %>% complete.cases()

## Summary statistics
hist(all.df$age)
hist(all.df$duration_months)

median(na.omit(all.df$duration_months))
range(na.omit(all.df$duration_months))

```

Unfortunately it looks like there's a lot of missingness in the data. For the metadata that might be useful in modeling, the ages look nice, almost a normal distribution. The duration in study median is at 17 months, min is 2 months and max is 600 months?! that's 50 years lol gotta be a mistake...

Right off the bat let's clean up some of the variables by coding them.

```{r cleaning_codeprptype}
## code prptype as a factor
all.df$prptype <- as.character(all.df$prptype)
all.df$prpcode[all.df$prptype == "cascade"] <- 0
all.df$prpcode[all.df$prptype == "biomet"] <- 1
all.df$prpcode[all.df$prptype == "abi"] <- 2
all.df$prpcode <- as.factor(all.df$prpcode)

## code pt
all.df$pt <- as.character(all.df$pt)
all.df$pt[all.df$pt == "no"] <- 0
all.df$pt[all.df$pt == "yes"] <- 1

## code cortisone_yn
all.df$cortisone_yn <- as.character(all.df$cortisone_yn)
all.df$cortisone_yn[all.df$cortisone_yn == "no"] <- 0
all.df$cortisone_yn[all.df$cortisone_yn == "yes"] <- 1

```

Now let's take a look at the response variables we have. We already know there's going to be missingness from the summary statistics above, but I want to see the trends over time (as lines and as boxplots) to see if there's anything  interesting there.

```{r summarystats_notlikert}
# make a line plot to visualize trend over time
plot.overall.trend <- function(df){
  ggplot(df, aes(x=variable, y=value, factor(prpcode))) +
  stat_summary(aes(group=patientid, color = as.factor(prpcode)), alpha=0.5, fun.y=mean, geom="line")
}

# make a boxplot of the values to visualize variance and trend over time
plot.boxplot <- function(df){
  ggplot(df, aes(x=variable, y=value)) +
  geom_boxplot(aes(fill = factor(prpcode)))
}

# make plot of the subset of patients trend over time (whatever subset you want)
plot.slice.trend <- function(df, slice){
  ggplot(subset(df, patientid %in% slice), 
         aes(x=variable,y=value)) +
    geom_point(aes(color=prpcode), size=3) +
    stat_summary(aes(group=patientid, color=prpcode), fun.y=mean, geom="line")
}

## subset the data for the 'easy' variables of patientid, timepoints, and the coded prp type
timecols <- c('time0','time6','time12', 'time26', 'time52')
time.prptype.df <- all.df[, c('patientid',timecols,'prpcode')]

## plot the trends over time for each patient (the other scale, not the likert scale)
meltedSubset <- melt(as.data.frame(time.prptype.df), id=c('patientid','prpcode'))

(response.trend <- plot.overall.trend(meltedSubset))
(response.box <- plot.boxplot(meltedSubset))
#ggsave("../results/summary_response.png", arrangeGrob(response.trend, response.box))

## plot a slice of the dataframe to visualize it better
slice <- c(1,2,3,20,21,22,130,131,132)
plot.slice.trend(meltedSubset, all.df$patientid[slice])  # note: you can change this "[1:10]" to however many or few you want! 
#ggsave("../results/summary_response_example.png")
```

Uh oh. The "hairball" shows variance in the range that people used to rate their health. It looks like some people really use the full 0-100 scale, and others stick pretty close to the first number they wrote down. I can't visually pick out any meaningful trends, so we shouldn't get our hopes up that there's anything to find in this data.

Maybe we'll be safe if we use the Likert scale responses, because they're a smaller range (1-6)?

```{r summarystats_likert}
## same as above but with the likert
likertcols <- c('time6lpt', 'time12lpt', 'time26lpt', 'time52lpt')
time.likert.df <- all.df[, c('patientid',likertcols,'prpcode')]
meltedLikert <- melt(as.data.frame(time.likert.df), id=c('patientid','prpcode'))

(likert.trend <- plot.overall.trend(meltedLikert))
(likert.box <- plot.boxplot(meltedLikert))
#ggsave("../results/summary_likert.png", arrangeGrob(likert.trend, likert.box))

```

Still a hairball, still too much variance in how people rated their response. I think we're going to have to just go with the binary response I made in Excel, maybe scaling somehow as percent improvement respective to each patient.

```{r cleaning_coderesponse, eval=FALSE}
## NOTE: THE FOLLOWING TWO FUNCTIONS ARE CODED IN BAD FORM... I HARD CODED THE TIME VARIABLES TO USE, SO YOU'LL HAVE TO CHANGE THOSE IF YOU WANT TO USE A DIFFERENT TIME SCALE (LIKERT, ETC)

# find first time point
find.first.time.point <- function(row){
  # sort column names alphanumeric so that they're 'in order'
  #if (order == "first"){
  #  cols <- mixedsort(cols)
  #} else if (order == "last"){
  #  cols <- rev(mixedsort(cols))
  #}
  
  #cols <- timecols  # timepoint response values
  cols <- likertcols  # likert response values
  cols <- mixedsort(cols)
  timepoints <- row[cols]
  print(timepoints)
  
  if (length(na.omit(timepoints)) == 0){ # if all NA then skip
    print("All timepoints are NA!")
    result <- NA
    return(result)
  } else { # go backwards until not NA
    for (timepoint in cols){
      if (is.na(timepoints[timepoint]) == FALSE){
        result <- timepoints[[timepoint]]
        result <- trimws(result)
        return(result)
      }else{
        next
      } # close if-then to check if timepoint is last
    } # close for loop
  } # close 
}

# find last time point
find.last.time.point <- function(row){
  # sort column names alphanumeric so that they're 'in order'
  
  #cols <- timecols  # timepoint response values
  cols <- likertcols  # likert response values
  
  cols <- rev(mixedsort(cols))
  timepoints <- row[cols]
  print(timepoints)
  
  if (length(na.omit(timepoints)) == 0){ # if all NA then skip
    print("All timepoints are NA!")
    result <- NA
    return(result)
  } else { # go backwards until not NA
    for (timepoint in cols){
      if (is.na(timepoints[timepoint]) == FALSE){
        result <- timepoints[[timepoint]]
        result <- trimws(result)
        return(result)
      }else{
        next
      } # close if-then to check if timepoint is last
    } # close for loop
  } # close 
}

# code 1 if last time point > first time point, 0 if not
code.progress <- function(row){
  first.pt <- row['firsttimept']
  last.pt <- row['lasttimept']
  
  print(first.pt)
  print(last.pt)
  
  if (is.na(first.pt) == TRUE){
    return(NA)
  } else if (first.pt < last.pt){
    return(1)
  } else {
    return(0)
  }
}

#all.df$firsttimept <- apply(all.df, 1, find.first.time.point)
#all.df$lasttimept <- apply(all.df, 1, find.last.time.point)
#all.df$codedprog <- apply(all.df, 1, code.progress)

#all.df$firsttimept.likert <- apply(all.df, 1, find.first.time.point)
#all.df$lasttimept.likert <- apply(all.df, 1, find.last.time.point)
#all.df$codedprog.likert <- apply(all.df, 1, code.progress)

#write.csv(all.df, file = "./data/prp_tendon_cleaned2_reshaped_delim_20170305.csv")
```

```{r cleaning_pctresponse, eval=FALSE}
## note: I gave up on this section and just did it in excel! :)

## BASELINE SUBTRACTION
baseline.subtraction <- function(row){
  # get baseline response (first time point)
  
  #cols <- timecols  # timepoint response values
  cols <- likertcols  # likert response values
  
  cols <- rev(mixedsort(cols))
  timepoints <- row[cols]

  baseline <- as.numeric(find.first.time.point(timepoints))
  #print(baseline)
  
  new.timepoints <- list()  # intialize empty vector to store baseline-substracted timepoints
  
  # subtract baseline from other time points
  for (i in timepoints){
    value <- as.numeric(timepoints[i])
    #print(value) 
    
    if (is.na(value) == TRUE){
      new.timepoints[i] <- NA
    } else {
      new.timepoints[i] <- value-baseline
    }
  }
  print(timepoints)
  print(new.timepoints)
  return(new.timepoints)
}

## TIMEPOINTS TO PERCENTAGES
#to.percentages <- function{
  # find maximum response
#}

#baselinesub.df <- apply(all.df, 1, to.percentages)

```

Let's look at what scaling/normalizing patients to their own baseline looks like. 

```{r summarystats_cleaneddata}
# baseline-subtracted 0-100 scaled values
baselinecols <- c('baseline0', 'baseline6', 'baseline12', 'baseline26', 'baseline52')
baseline.df <- all.df[, c('patientid',baselinecols,'prpcode')]
meltedBaseline <- melt(as.data.frame(baseline.df), id=c('patientid','prpcode'))

(baseline.trend <- plot.overall.trend(meltedBaseline))
(baseline.box <- plot.boxplot(meltedBaseline))
#ggsave("../results/summary_baseline.png", arrangeGrob(baseline.trend, baseline.box))

# baseline-subtracted pct scaled values
baselinepctcols <- c('pct.base0', 'pct.base6', 'pct.base12', 'pct.base26', 'pct.base52')
baselinepct.df <- all.df[, c('patientid',baselinepctcols,'prpcode')]
meltedBaselinePct <- melt(as.data.frame(baselinepct.df), id=c('patientid','prpcode'))

(pct.trend <- plot.overall.trend(meltedBaselinePct))
(pct.box <- plot.boxplot(meltedBaselinePct))
#ggsave("../results/summary_pct.png", arrangeGrob(pct.trend, pct.box))

# baseline-subtracted likert
baselinelikertcols <- c('baseline.likert6','baseline.likert12','baseline.likert26','baseline.likert52')
baselinelikert.df <- all.df[, c('patientid',baselinelikertcols,'prpcode')]
meltedBaselineLikert <- melt(as.data.frame(baselinelikert.df), id=c('patientid','prpcode'))

(base.likert.trend <- plot.overall.trend(meltedBaselineLikert))
(base.likert.box <- plot.boxplot(meltedBaselineLikert))
#ggsave("../results/summary_baselikert.png", arrangeGrob(base.likert.trend, base.likert.box))


# baseline-subtracted likert
pctlikertcols <- c('pct.likert0', 'pct.likert6', 'pct.likert12', 'pct.likert26', 'pct.likert52')
pctlikert.df <- all.df[, c('patientid',pctlikertcols,'prpcode')]
meltedPctLikert <- melt(as.data.frame(pctlikert.df), id=c('patientid','prpcode'))

(pct.likert.trend <- plot.overall.trend(meltedPctLikert))
(pct.likert.box <- plot.boxplot(meltedPctLikert))
#ggsave("../results/summary_pctlikert.png", arrangeGrob(pct.likert.trend, pct.likert.box))


```

Ooowhee, look at those boxplots. I think this pretty much puts the nail in the coffin -- we're not going to be able to get anything out of this.

Let's try anyway!

```{r lasso}
##
## Lasso regression using metadata as potential contributing variables
##

# subset the dataframe for the lasso features and response variables
#lassocols <- c('codedprog', 'prpcode', 'injurytype', 'dxcode', 'pt', 'cortisone_yn','nitropatch', 'surgery', 'coldlaser', 'massage', 'acupuncture', 'chiropractor', 'age','race', 'gender', 'athlete_status', 'primary_sport', 'duration_months')
# couldn't use all the variables above, too much NA
lassocols <- c('codedprog', 'prpcode', 'dxcode', 'pt', 'cortisone_yn', 'age', 'gender_num', 'duration_months')
lasso.df <- all.df[,lassocols]
lasso.df <- subset(lasso.df, prpcode != 2)
lasso.df <- na.omit(lasso.df)

# convert everything to factors or numeric as necessary
lasso.df$codedprog <- as.factor(lasso.df$codedprog)
lasso.df$prpcode <- as.factor(lasso.df$prpcode)
lasso.df$dxcode <- as.factor(lasso.df$dxcode)
lasso.df$pt <- as.factor(lasso.df$pt)
lasso.df$cortisone_yn <- as.factor(lasso.df$cortisone_yn)
lasso.df$age <- as.numeric(lasso.df$age)
lasso.df$gender_num <- as.factor(lasso.df$gender_num)
lasso.df$duration_months <- as.numeric(lasso.df$duration_months)
#lasso.df$time0 <- as.numeric(lasso.df$time0)

# expand the factors to dummy variables
xfactors <- model.matrix(codedprog ~ prpcode + dxcode + pt + cortisone_yn + gender_num, data=lasso.df)[, -1]

# join the dummy variables with the continuous variables
x <- as.matrix(data.frame(lasso.df$age, lasso.df$duration_months, xfactors))

# create outcome vector
y <- as.factor(lasso.df$codedprog)

# Split into train and test, just doing two-fold I guess
x <- x[sample(nrow(x)),] # shuffle data
test <- sample(1:nrow(x), nrow(x)/2)
train <- (-test)
y.test <- y[test]

# make a grid of lambda values to test over
grid <- 10^seq(5,-2,length=100)

# finally, fit the lasso model
lasso.mod <- glmnet(x[train,], as.factor(y[train]), alpha=1, family="binomial", lambda=grid)

# visualize results of the lasso, note coefficient paths
jpeg('../results/lasso_coefficientpaths2.jpg')
plot(lasso.mod,xvar="lambda",col=c(1:ncol(x)),lwd=c(1,2,3))
legend('topright',colnames(x),col=c(1:ncol(x)),bty='n',lwd=c(1,2,3))
coef(lasso.mod)[, 10]

# now pick the best lambda value for the train data
set.seed(1)
cv.out <- cv.glmnet(x[train,],y[train],alpha=1,family="binomial")
jpeg('../results/lasso_bestlambda.jpg')
plot(cv.out)
bestlam <- cv.out$lambda.min

# fit the model with the best lambda from training to the test data and check the regression performance
lasso.probs <- predict(lasso.mod,s=bestlam,type="response",newx=x[test,])

lasso.pred <- rep("0",length(test))
lasso.pred[lasso.probs>.5]="1"
table(lasso.pred,y.test)

out <- glmnet(x, y, alpha=1, family="binomial", lambda=grid)
lasso.coef <- predict(out,type="coefficient",s=bestlam)[1:15,]
lasso.coef
lasso.coef[lasso.coef!=0]
```

I get different results each time I run this code, based on my folds I think. The folds definitely aren't set up ideally (which I think should be stratefied maybe using library(caret)) so that is probably also affecting the robustness of the model fitting. If I have different subsets getting divided into the folds unequally, then I'd imagine that affects which coefficients are predictive.
Anyway, it seems the most informative coefficients are injection site, cortisone treatment, and gender. I'm not sure how "real" that is, though, since the results change each time. I'm surprised age doesn't factor here. There were also a number of other variables that might have been useful in modeling, but had too many NA or weren't easily coded, especially considering all the data cleaning on the response variables I did.

Lastly, let's look at the timecourse analysis and see if we can pick apart any significant trends over time.

```{r timepoint}
##
## TIMECOURSE ANALYSIS
##
# Too many NA's, not sure we can get anything from this

do.timecourse <- function(df,subset,timecourse){
  ## prepare matrix for modeling
  matrixSubset <- as.matrix(df[,subset])
  colnames(matrixSubset) <- timecourse
  
  ## remove na, keeping only complete timecourses
  matrixSubset.complete <- matrixSubset[complete.cases(matrixSubset),]
  
  ## creating full and null models
  de_obj <- build_study(data=matrixSubset.complete, tme=timecourse, sampling = "timecourse")
  full_matrix <- fullMatrix(de_obj)
  null_matrix <- nullMatrix(de_obj)
  prpcode.expr <- exprs(de_obj)  # seems to be the same as the expression matrix
  
  ## fitting the data
  ef_obj <- fit_models(de_obj, stat.type = "odp")
  alt_fitted <- fitFull(ef_obj)
  null_fitted <- fitNull(ef_obj)
  
  ## significance analysis
  #de_odp <- odp(ef_obj, bs.its = 50, verbose = FALSE, n.mods = 50)  # optimal discovery procedure (odp) doesn't work
  de_lrt <- lrt(de_obj, nullDistn = "normal")  # likelihood ratio test does work
  
  return(de_lrt)
}

timecourse.num <- c(0,6,12,26,52)  # timecourse values for the 0-100 scale
likert.time <- c(6,12,26,52)  # timecourse values for the likert scale

(timecourse.prp <- do.timecourse(all.df, timecols, timecourse.num))

(baseline.timecourse.prp <- do.timecourse(all.df, baselinecols, timecourse.num))
(baseline.timecourse.prp0 <- do.timecourse(subset(all.df, prpcode == 0), baselinecols, timecourse.num))
(baseline.timecourse.prp1 <- do.timecourse(subset(all.df, prpcode == 1), baselinecols, timecourse.num))
(baseline.timecourse.prp2 <- do.timecourse(subset(all.df, prpcode == 2), baselinecols, timecourse.num))


(baselinepct.timecourse <- do.timecourse(all.df, baselinepctcols, timecourse.num))
(baselikert.timecourse <- do.timecourse(all.df, baselinelikertcols, likert.time))

```

