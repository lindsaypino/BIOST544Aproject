---
title: "analysisLKP.Rmd"
author: "LK Pino"
date: "March 5, 2017"
output: html_document
---

Hi guys

I'm moving my \*.R code into \*.Rmd so that I can make comments for my write up, and because the code is getting a little long and I wanted to organize!

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache=TRUE)
options(digits = 3) ## Formats output to 3 digits
library(gtools)
library(ggplot2)
library(dplyr)
library(data.table)
library(reshape2)
source("http://bioconductor.org/biocLite.R")  # for timecourse analysis
biocLite("edge")  # for timecourse analysis
library(edge)  # for timecourse analysis
library(gridExtra)

dir <- getwd()
setwd(dir)
#all.df <- read.csv("../data/prp_tendon_cleaned2_reshaped_delim.csv")
all.df <- read.csv("../data/prp_tendon_cleaned2_reshaped_delim_20170310.csv")
```

```{r dataframe_readin}
## Subset for the variables I know
cols <- colnames(all.df)
keepcols <- c(1,2,3,4,5,6,28,29,30,31,33,34,36,37,38,40,41,42,43,44,45,46,49,50,52,53,55,56,57,58)
subset.df <- all.df[, keepcols]
# note: missing prptype for pt AGFT199 -- discarded in excel
```

```{r summarystats_meta}
## Missingness by feature, ie how many N/As per column
apply(subset.df, 2, function(x){sum(is.na(x))}) 
complete <- subset.df %>% complete.cases()
mean(complete)  ## proportion of cases complete
length(unique(subset.df$patientid))  ## total unique patients

## subset for metadata features
meta.df <- subset.df %>% select(patientid, treatment, age, race, gender_num, duration_months)  # subset for features we'll be using 
apply(meta.df, 2, function(x){sum(is.na(x))}) 
complete <- meta.df %>% complete.cases()

## Summary statistics
ages <- subset.df %>% 
  group_by(as.factor(gender_num)) %>% 
  summarise(mean(duration_months))

hist(subset.df$age)
hist(subset.df$duration_months)

median(na.omit(subset.df$duration_months))
range(na.omit(subset.df$duration_months))

```

ages look nice, almost normal distribution.

duration in study median at 17 months, min is 2 months and max is 600 months?! that's 50 years lol gotta be a mistake...

```{r cleaning_codeprptype}
## code prptype as a factor
all.df$prptype <- as.character(all.df$prptype)
all.df$prpcode[all.df$prptype == "cascade"] <- 1
all.df$prpcode[all.df$prptype == "biomet"] <- 2
all.df$prpcode[all.df$prptype == "abi"] <- 0
all.df$prpcode <- as.factor(all.df$prpcode)
```

```{r summarystats_notlikert}
# make a line plot to visualize trend over time
plot.overall.trend <- function(df){
  ggplot(df, aes(x=variable, y=value, factor(prpcode))) +
  stat_summary(aes(group=patientid, color = as.factor(prpcode)), alpha=0.5, fun.y=mean, geom="line")
}

# make a boxplot of the values to visualize variance and trend over time
plot.boxplot <- function(df){
  ggplot(df, aes(x=variable, y=value)) +
  geom_boxplot(aes(fill = factor(prpcode)))
}

# make plot of the subset of patients trend over time (whatever subset you want)
plot.slice.trend <- function(df, slice){
  ggplot(subset(df, patientid %in% slice), 
         aes(x=variable,y=value)) +
    geom_point(aes(color=patientid), size=3) +
    stat_summary(aes(group=patientid, color=patientid), fun.y=mean, geom="line")
}

## subset the data for the 'easy' variables of patientid, timepoints, and the coded prp type
timecols <- c('time0','time6','time12', 'time26', 'time52')
time.prptype.df <- all.df[, c('patientid',timecols,'prpcode')]

## plot the trends over time for each patient (the other scale, not the likert scale)
meltedSubset <- melt(as.data.frame(time.prptype.df), id=c('patientid','prpcode'))

response.trend <- plot.overall.trend(meltedSubset)
response.box <- plot.boxplot(meltedSubset)
ggsave("../results/summary_response.png", arrangeGrob(response.trend, response.box))

## plot a slice of the dataframe to visualize it better
plot.slice.trend(baseline.df, baseline.df$patientid[1:10])  # note: you can change this "[1:10]" to however many or few you want! 
```

"hairball" shows variance in the range that people used to rate their health. try likert?

```{r summarystats_likert}
## same as above but with the likert
likertcols <- c('time6lpt', 'time12lpt', 'time26lpt', 'time52lpt')
time.likert.df <- all.df[, c('patientid',likertcols,'prpcode')]
meltedLikert <- melt(as.data.frame(time.likert.df), id=c('patientid','prpcode'))

likert.trend <- plot.overall.trend(meltedLikert)
likert.box <- plot.boxplot(meltedLikert)
ggsave("../results/summary_likert.png", arrangeGrob(likert.trend, likert.box))

```

still a hairball, still too much variance in how people rated their response. think we're going to have to just go with the binary response, maybe scaling somehow as percent improvement respective to each patient.

```{r cleaning_coderesponse, eval=FALSE}
## NOTE: THE FOLLOWING TWO FUNCTIONS ARE CODED IN BAD FORM... I HARD CODED THE TIME VARIABLES TO USE, SO YOU'LL HAVE TO CHANGE THOSE IF YOU WANT TO USE A DIFFERENT TIME SCALE (LIKERT, ETC)

# find first time point
find.first.time.point <- function(row){
  # sort column names alphanumeric so that they're 'in order'
  #if (order == "first"){
  #  cols <- mixedsort(cols)
  #} else if (order == "last"){
  #  cols <- rev(mixedsort(cols))
  #}
  
  #cols <- timecols  # timepoint response values
  cols <- likertcols  # likert response values
  cols <- mixedsort(cols)
  timepoints <- row[cols]
  print(timepoints)
  
  if (length(na.omit(timepoints)) == 0){ # if all NA then skip
    print("All timepoints are NA!")
    result <- NA
    return(result)
  } else { # go backwards until not NA
    for (timepoint in cols){
      if (is.na(timepoints[timepoint]) == FALSE){
        result <- timepoints[[timepoint]]
        result <- trimws(result)
        return(result)
      }else{
        next
      } # close if-then to check if timepoint is last
    } # close for loop
  } # close 
}

# find last time point
find.last.time.point <- function(row){
  # sort column names alphanumeric so that they're 'in order'
  
  #cols <- timecols  # timepoint response values
  cols <- likertcols  # likert response values
  
  cols <- rev(mixedsort(cols))
  timepoints <- row[cols]
  print(timepoints)
  
  if (length(na.omit(timepoints)) == 0){ # if all NA then skip
    print("All timepoints are NA!")
    result <- NA
    return(result)
  } else { # go backwards until not NA
    for (timepoint in cols){
      if (is.na(timepoints[timepoint]) == FALSE){
        result <- timepoints[[timepoint]]
        result <- trimws(result)
        return(result)
      }else{
        next
      } # close if-then to check if timepoint is last
    } # close for loop
  } # close 
}

# code 1 if last time point > first time point, 0 if not
code.progress <- function(row){
  first.pt <- row['firsttimept']
  last.pt <- row['lasttimept']
  
  print(first.pt)
  print(last.pt)
  
  if (is.na(first.pt) == TRUE){
    return(NA)
  } else if (first.pt < last.pt){
    return(1)
  } else {
    return(0)
  }
}

all.df$firsttimept <- apply(all.df, 1, find.first.time.point)
all.df$lasttimept <- apply(all.df, 1, find.last.time.point)
all.df$codedprog <- apply(all.df, 1, code.progress)

all.df$firsttimept.likert <- apply(all.df, 1, find.first.time.point)
all.df$lasttimept.likert <- apply(all.df, 1, find.last.time.point)
all.df$codedprog.likert <- apply(all.df, 1, code.progress)

#write.csv(all.df, file = "./data/prp_tendon_cleaned2_reshaped_delim_20170305.csv")
```

```{r cleaning_pctresponse, eval=FALSE}
## note: I gave up on this section and just did it in excel! c:

## BASELINE SUBTRACTION
baseline.subtraction <- function(row){
  # get baseline response (first time point)
  
  #cols <- timecols  # timepoint response values
  cols <- likertcols  # likert response values
  
  cols <- rev(mixedsort(cols))
  timepoints <- row[cols]

  baseline <- as.numeric(find.first.time.point(timepoints))
  #print(baseline)
  
  new.timepoints <- list()  # intialize empty vector to store baseline-substracted timepoints
  
  # subtract baseline from other time points
  for (i in timepoints){
    value <- as.numeric(timepoints[i])
    #print(value) 
    
    if (is.na(value) == TRUE){
      new.timepoints[i] <- NA
    } else {
      new.timepoints[i] <- value-baseline
    }
  }
  print(timepoints)
  print(new.timepoints)
  return(new.timepoints)
}

## TIMEPOINTS TO PERCENTAGES
#to.percentages <- function{
  # find maximum response
#}

#baselinesub.df <- apply(all.df, 1, to.percentages)

```

```{r summarystats_cleaneddata}
# baseline-subtracted 0-100 scaled values
baselinecols <- c('baseline0', 'baseline6', 'baseline12', 'baseline26', 'baseline52')
baseline.df <- all.df[, c('patientid',baselinecols,'prpcode')]
meltedBaseline <- melt(as.data.frame(baseline.df), id=c('patientid','prpcode'))

baseline.trend <- plot.overall.trend(meltedBaseline)
baseline.box <- plot.boxplot(meltedBaseline)
ggsave("../results/summary_baseline.png", arrangeGrob(baseline.trend, baseline.box))

# baseline-subtracted pct scaled values
baselinepctcols <- c('pct.base0', 'pct.base6', 'pct.base12', 'pct.base26', 'pct.base52')
baselinepct.df <- all.df[, c('patientid',baselinepctcols,'prpcode')]
meltedBaselinePct <- melt(as.data.frame(baselinepct.df), id=c('patientid','prpcode'))

pct.trend <- plot.overall.trend(meltedBaselinePct)
pct.box <- plot.boxplot(meltedBaselinePct)
ggsave("../results/summary_pct.png", arrangeGrob(pct.trend, pct.box))

# baseline-subtracted likert
baselinelikertcols <- c('baseline.likert6','baseline.likert12','baseline.likert26','baseline.likert52')
baselinelikert.df <- all.df[, c('patientid',baselinelikertcols,'prpcode')]
meltedBaselineLikert <- melt(as.data.frame(baselinelikert.df), id=c('patientid','prpcode'))

base.likert.trend <- plot.overall.trend(meltedBaselineLikert)
base.likert.box <- plot.boxplot(meltedBaselineLikert)
ggsave("../results/summary_baselikert.png", arrangeGrob(base.likert.trend, base.likert.box))


# baseline-subtracted likert
pctlikertcols <- c('pct.likert0', 'pct.likert6', 'pct.likert12', 'pct.likert26', 'pct.likert52')
pctlikert.df <- all.df[, c('patientid',pctlikertcols,'prpcode')]
meltedPctLikert <- melt(as.data.frame(pctlikert.df), id=c('patientid','prpcode'))

pct.likert.trend <- plot.overall.trend(meltedPctLikert)
pct.likert.box <- plot.boxplot(meltedPctLikert)
ggsave("../results/summary_pctlikert.png", arrangeGrob(pct.likert.trend, pct.likert.box))


```

```{r lasso}
#subset the dataframe for the lasso features and response variables

```

```{r timepoint}
##
## TIMECOURSE ANALYSIS
##
## For now I'm not working much on this, 
## I'll have to think about it a little more. Namely, the package was 
## designed to be used on data that has many genes, and finding the genes
## that trend significantly over time. We don't have genes here, just
## the two groups. Maybe we don't need to do the significance analysis then?


## prepare matrix for modeling
matrixSubset <- as.matrix(as.data.frame(lapply(time.prptype.df[,timecols], as.numeric)))
matrixSubset <- as.matrix(as.data.frame(lapply(time.likert.df[,timecols], as.numeric)))

## creating full and null models
library(splines)
timevariable <- c(0,6,12,26,52)
colnames(matrixSubset) <- timevariable
de_obj <- build_study(data = matrixSubset, tme=timevariable, sampling = "timecourse")
full_matrix <- fullMatrix(de_obj)
null_matrix <- nullMatrix(de_obj)
prpcode.expr <- exprs(de_obj)  # seems to be the same as the expression matrix


## fitting the data

ef_obj <- fit_models(de_obj, stat.type = "odp")
alt_fitted <- fitFull(ef_obj)
null_fitted <- fitNull(ef_obj)


## significance analysis


#de_odp <- odp(ef_obj, bs.its = 50, verbose = FALSE, n.mods = 50)  # optimal discovery procedure (odp) doesn't work
de_lrt <- lrt(de_obj, nullDistn = "normal")  # likelihood ratio test does work
summary(de_lrt)

sig_results <- qvalueObj(de_lrt)
qvals <- sig_results$qvalues
pvals <- sig_results$pvalues
lfdr <- sig_results$lfdr
pi0 <- sig_results$pi0


# list of all significant genes at an FDr of 0.1
fdr.level <- 0.1
sigGenes <- qvals < fdr.level

```
