---
title: "analysisLKP.Rmd"
author: "LK Pino"
date: "March 5, 2017"
output: html_document
---

Hi guys

I'm moving my \*.R code into \*.Rmd so that I can make comments for my write up, and because the code is getting a little long and I wanted to organize!

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache=TRUE)
options(digits = 3) ## Formats output to 3 digits
library(gtools)
library(ggplot2)
library(dplyr)
library(data.table)
library(reshape2)
#source("http://bioconductor.org/biocLite.R")  # for timecourse analysis
#biocLite("edge")  # for timecourse analysis
library(edge)  # for timecourse analysis
library(splines)
library(gridExtra)
library(glmnet)  # for lasso

dir <- getwd()
setwd(dir)
all.df <- read.csv("../data/prp_tendon_cleaned2_reshaped_delim_20170310.csv")  # data frame cleaned and 'normalized' in excel
```

```{r dataframe_readin}
## Subset for the variables I know
#cols <- colnames(all.df)
#keepcols <- c(1,2,3,4,5,6,28,29,30,31,33,34,36,37,38,40,41,42,43,44,45,46,49,50,52,53,55,56,57,58)
#subset.df <- all.df[, keepcols]
# note: missing prptype for pt AGFT199 -- discarded in excel
```

```{r summarystats_meta}
## Missingness by feature, ie how many N/As per column
apply(all.df, 2, function(x){sum(is.na(x))}) 
complete <- all.df %>% complete.cases()
mean(complete)  ## proportion of cases complete
length(unique(all.df$patientid))  ## total unique patients

## subset for metadata features
meta.df <- all.df %>% select(patientid, treatment, age, race, gender_num, duration_months)  # subset for features we'll be using 
apply(meta.df, 2, function(x){sum(is.na(x))}) 
complete <- meta.df %>% complete.cases()

## Summary statistics
ages <- all.df %>% 
  group_by(as.factor(gender_num)) %>% 
  summarise(mean(duration_months))

hist(all.df$age)
hist(all.df$duration_months)

median(na.omit(all.df$duration_months))
range(na.omit(all.df$duration_months))

```

ages look nice, almost normal distribution.

duration in study median at 17 months, min is 2 months and max is 600 months?! that's 50 years lol gotta be a mistake...

```{r cleaning_codeprptype}
## code prptype as a factor
all.df$prptype <- as.character(all.df$prptype)
all.df$prpcode[all.df$prptype == "cascade"] <- 0
all.df$prpcode[all.df$prptype == "biomet"] <- 1
all.df$prpcode[all.df$prptype == "abi"] <- 2
all.df$prpcode <- as.factor(all.df$prpcode)

## code pt
all.df$pt <- as.character(all.df$pt)
all.df$pt[all.df$pt == "no"] <- 0
all.df$pt[all.df$pt == "yes"] <- 1

## code cortisone_yn
all.df$cortisone_yn <- as.character(all.df$cortisone_yn)
all.df$cortisone_yn[all.df$cortisone_yn == "no"] <- 0
all.df$cortisone_yn[all.df$cortisone_yn == "yes"] <- 1

```

```{r summarystats_notlikert}
# make a line plot to visualize trend over time
plot.overall.trend <- function(df){
  ggplot(df, aes(x=variable, y=value, factor(prpcode))) +
  stat_summary(aes(group=patientid, color = as.factor(prpcode)), alpha=0.5, fun.y=mean, geom="line")
}

# make a boxplot of the values to visualize variance and trend over time
plot.boxplot <- function(df){
  ggplot(df, aes(x=variable, y=value)) +
  geom_boxplot(aes(fill = factor(prpcode)))
}

# make plot of the subset of patients trend over time (whatever subset you want)
plot.slice.trend <- function(df, slice){
  ggplot(subset(df, patientid %in% slice), 
         aes(x=variable,y=value)) +
    geom_point(aes(color=prpcode), size=3) +
    stat_summary(aes(group=patientid, color=prpcode), fun.y=mean, geom="line")
}

## subset the data for the 'easy' variables of patientid, timepoints, and the coded prp type
timecols <- c('time0','time6','time12', 'time26', 'time52')
time.prptype.df <- all.df[, c('patientid',timecols,'prpcode')]

## plot the trends over time for each patient (the other scale, not the likert scale)
meltedSubset <- melt(as.data.frame(time.prptype.df), id=c('patientid','prpcode'))

response.trend <- plot.overall.trend(meltedSubset)
response.box <- plot.boxplot(meltedSubset)
#ggsave("../results/summary_response.png", arrangeGrob(response.trend, response.box))

## plot a slice of the dataframe to visualize it better
slice <- c(1,2,3,20,21,22,130,131,132)
plot.slice.trend(meltedSubset, all.df$patientid[slice])  # note: you can change this "[1:10]" to however many or few you want! 
#ggsave("../results/summary_response_example.png")
```

"hairball" shows variance in the range that people used to rate their health. try likert?

```{r summarystats_likert}
## same as above but with the likert
likertcols <- c('time6lpt', 'time12lpt', 'time26lpt', 'time52lpt')
time.likert.df <- all.df[, c('patientid',likertcols,'prpcode')]
meltedLikert <- melt(as.data.frame(time.likert.df), id=c('patientid','prpcode'))

likert.trend <- plot.overall.trend(meltedLikert)
likert.box <- plot.boxplot(meltedLikert)
ggsave("../results/summary_likert.png", arrangeGrob(likert.trend, likert.box))

```

still a hairball, still too much variance in how people rated their response. think we're going to have to just go with the binary response, maybe scaling somehow as percent improvement respective to each patient.

```{r cleaning_coderesponse, eval=FALSE}
## NOTE: THE FOLLOWING TWO FUNCTIONS ARE CODED IN BAD FORM... I HARD CODED THE TIME VARIABLES TO USE, SO YOU'LL HAVE TO CHANGE THOSE IF YOU WANT TO USE A DIFFERENT TIME SCALE (LIKERT, ETC)

# find first time point
find.first.time.point <- function(row){
  # sort column names alphanumeric so that they're 'in order'
  #if (order == "first"){
  #  cols <- mixedsort(cols)
  #} else if (order == "last"){
  #  cols <- rev(mixedsort(cols))
  #}
  
  #cols <- timecols  # timepoint response values
  cols <- likertcols  # likert response values
  cols <- mixedsort(cols)
  timepoints <- row[cols]
  print(timepoints)
  
  if (length(na.omit(timepoints)) == 0){ # if all NA then skip
    print("All timepoints are NA!")
    result <- NA
    return(result)
  } else { # go backwards until not NA
    for (timepoint in cols){
      if (is.na(timepoints[timepoint]) == FALSE){
        result <- timepoints[[timepoint]]
        result <- trimws(result)
        return(result)
      }else{
        next
      } # close if-then to check if timepoint is last
    } # close for loop
  } # close 
}

# find last time point
find.last.time.point <- function(row){
  # sort column names alphanumeric so that they're 'in order'
  
  #cols <- timecols  # timepoint response values
  cols <- likertcols  # likert response values
  
  cols <- rev(mixedsort(cols))
  timepoints <- row[cols]
  print(timepoints)
  
  if (length(na.omit(timepoints)) == 0){ # if all NA then skip
    print("All timepoints are NA!")
    result <- NA
    return(result)
  } else { # go backwards until not NA
    for (timepoint in cols){
      if (is.na(timepoints[timepoint]) == FALSE){
        result <- timepoints[[timepoint]]
        result <- trimws(result)
        return(result)
      }else{
        next
      } # close if-then to check if timepoint is last
    } # close for loop
  } # close 
}

# code 1 if last time point > first time point, 0 if not
code.progress <- function(row){
  first.pt <- row['firsttimept']
  last.pt <- row['lasttimept']
  
  print(first.pt)
  print(last.pt)
  
  if (is.na(first.pt) == TRUE){
    return(NA)
  } else if (first.pt < last.pt){
    return(1)
  } else {
    return(0)
  }
}

all.df$firsttimept <- apply(all.df, 1, find.first.time.point)
all.df$lasttimept <- apply(all.df, 1, find.last.time.point)
all.df$codedprog <- apply(all.df, 1, code.progress)

all.df$firsttimept.likert <- apply(all.df, 1, find.first.time.point)
all.df$lasttimept.likert <- apply(all.df, 1, find.last.time.point)
all.df$codedprog.likert <- apply(all.df, 1, code.progress)

#write.csv(all.df, file = "./data/prp_tendon_cleaned2_reshaped_delim_20170305.csv")
```

```{r cleaning_pctresponse, eval=FALSE}
## note: I gave up on this section and just did it in excel! c:

## BASELINE SUBTRACTION
baseline.subtraction <- function(row){
  # get baseline response (first time point)
  
  #cols <- timecols  # timepoint response values
  cols <- likertcols  # likert response values
  
  cols <- rev(mixedsort(cols))
  timepoints <- row[cols]

  baseline <- as.numeric(find.first.time.point(timepoints))
  #print(baseline)
  
  new.timepoints <- list()  # intialize empty vector to store baseline-substracted timepoints
  
  # subtract baseline from other time points
  for (i in timepoints){
    value <- as.numeric(timepoints[i])
    #print(value) 
    
    if (is.na(value) == TRUE){
      new.timepoints[i] <- NA
    } else {
      new.timepoints[i] <- value-baseline
    }
  }
  print(timepoints)
  print(new.timepoints)
  return(new.timepoints)
}

## TIMEPOINTS TO PERCENTAGES
#to.percentages <- function{
  # find maximum response
#}

#baselinesub.df <- apply(all.df, 1, to.percentages)

```

```{r summarystats_cleaneddata}
# baseline-subtracted 0-100 scaled values
baselinecols <- c('baseline0', 'baseline6', 'baseline12', 'baseline26', 'baseline52')
baseline.df <- all.df[, c('patientid',baselinecols,'prpcode')]
meltedBaseline <- melt(as.data.frame(baseline.df), id=c('patientid','prpcode'))

baseline.trend <- plot.overall.trend(meltedBaseline)
baseline.box <- plot.boxplot(meltedBaseline)
ggsave("../results/summary_baseline.png", arrangeGrob(baseline.trend, baseline.box))

# baseline-subtracted pct scaled values
baselinepctcols <- c('pct.base0', 'pct.base6', 'pct.base12', 'pct.base26', 'pct.base52')
baselinepct.df <- all.df[, c('patientid',baselinepctcols,'prpcode')]
meltedBaselinePct <- melt(as.data.frame(baselinepct.df), id=c('patientid','prpcode'))

pct.trend <- plot.overall.trend(meltedBaselinePct)
pct.box <- plot.boxplot(meltedBaselinePct)
ggsave("../results/summary_pct.png", arrangeGrob(pct.trend, pct.box))

# baseline-subtracted likert
baselinelikertcols <- c('baseline.likert6','baseline.likert12','baseline.likert26','baseline.likert52')
baselinelikert.df <- all.df[, c('patientid',baselinelikertcols,'prpcode')]
meltedBaselineLikert <- melt(as.data.frame(baselinelikert.df), id=c('patientid','prpcode'))

base.likert.trend <- plot.overall.trend(meltedBaselineLikert)
base.likert.box <- plot.boxplot(meltedBaselineLikert)
ggsave("../results/summary_baselikert.png", arrangeGrob(base.likert.trend, base.likert.box))


# baseline-subtracted likert
pctlikertcols <- c('pct.likert0', 'pct.likert6', 'pct.likert12', 'pct.likert26', 'pct.likert52')
pctlikert.df <- all.df[, c('patientid',pctlikertcols,'prpcode')]
meltedPctLikert <- melt(as.data.frame(pctlikert.df), id=c('patientid','prpcode'))

pct.likert.trend <- plot.overall.trend(meltedPctLikert)
pct.likert.box <- plot.boxplot(meltedPctLikert)
ggsave("../results/summary_pctlikert.png", arrangeGrob(pct.likert.trend, pct.likert.box))


```

```{r lasso}
##
## Lasso regression using metadata as potential contributing variables
##

# subset the dataframe for the lasso features and response variables
#lassocols <- c('codedprog', 'prpcode', 'injurytype', 'dxcode', 'pt', 'cortisone_yn','nitropatch', 'surgery', 'coldlaser', 'massage', 'acupuncture', 'chiropractor', 'age','race', 'gender', 'athlete_status', 'primary_sport', 'duration_months')
# couldn't use all the variables above, too much NA
lassocols <- c('codedprog', 'prpcode', 'dxcode', 'pt', 'cortisone_yn', 'age', 'gender_num', 'duration_months')
lasso.df <- all.df[,lassocols]
lasso.df <- subset(lasso.df, prpcode != 2)
lasso.df <- na.omit(lasso.df)

# convert everything to factors or numeric as necessary
lasso.df$codedprog <- as.factor(lasso.df$codedprog)
lasso.df$prpcode <- as.factor(lasso.df$prpcode)
lasso.df$dxcode <- as.factor(lasso.df$dxcode)
lasso.df$pt <- as.factor(lasso.df$pt)
lasso.df$cortisone_yn <- as.factor(lasso.df$cortisone_yn)
lasso.df$age <- as.numeric(lasso.df$age)
lasso.df$gender_num <- as.factor(lasso.df$gender_num)
lasso.df$duration_months <- as.numeric(lasso.df$duration_months)
#lasso.df$time0 <- as.numeric(lasso.df$time0)

# expand the factors to dummy variables
xfactors <- model.matrix(codedprog ~ prpcode + dxcode + pt + cortisone_yn + gender_num, data=lasso.df)[, -1]

# join the dummy variables with the continuous variables
x <- as.matrix(data.frame(lasso.df$age, lasso.df$duration_months, xfactors))

# create outcome vector
y <- as.factor(lasso.df$codedprog)

# Split into train and test, just doing two-fold I guess
test <- sample(1:nrow(x), nrow(x)/2)
train <- (-test)
y.test <- y[test]

# make a grid of lambda values to test over
grid <- 10^seq(5,-2,length=100)

# finally, fit the lasso model
lasso.mod <- glmnet(x[train,], y[train], alpha=1, family="binomial", lambda=grid)

# visualize results of the lasso, note coefficient paths
jpeg('../results/lasso_coefficientpaths.jpg')
plot(lasso.mod,xvar="lambda",col=c(1:ncol(x)),lwd=c(1,2,3))
legend('topright',colnames(x),col=c(1:ncol(x)),bty='n',lwd=c(1,2,3))
coef(lasso.mod)[, 10]

# now pick the best lambda value for the train data
set.seed(1)
cv.out <- cv.glmnet(x[train,],y[train],alpha=1,family="binomial")
jpeg('../results/lasso_bestlambda.jpg')
plot(cv.out)
bestlam <- cv.out$lambda.min

# fit the model with the best lambda from training to the test data and check the regression performance
lasso.pred <- predict(lasso.mod,s=bestlam,newx=x[test,])
mean((lasso.pred-y.test)^2) # hmm, how to measure performance with a binary outcome...

out <- glmnet(x, y, alpha=1, family="binomial", lambda=grid)
lasso.coef <- predict(out,type="coefficients",s=bestlam)[1:15,]
lasso.coef
lasso.coef[lasso.coef!=0]
```

coefficients suggest injection site, specifically dxcode2 (lateral epicondylosis) and dxcode6 (proximal hamstring tendonosis), and gender are predictive.


```{r timepoint}
##
## TIMECOURSE ANALYSIS
##
# Too many NA's, not sure we can get anything from this

do.timecourse <- function(df,subset,timecourse){
  ## prepare matrix for modeling
  matrixSubset <- as.matrix(df[,subset])
  colnames(matrixSubset) <- timecourse
  
  ## remove na, keeping only complete timecourses
  matrixSubset.complete <- matrixSubset[complete.cases(matrixSubset),]
  
  ## creating full and null models
  de_obj <- build_study(data=matrixSubset.complete, tme=timecourse, sampling = "timecourse")
  full_matrix <- fullMatrix(de_obj)
  null_matrix <- nullMatrix(de_obj)
  prpcode.expr <- exprs(de_obj)  # seems to be the same as the expression matrix
  
  ## fitting the data
  ef_obj <- fit_models(de_obj, stat.type = "odp")
  alt_fitted <- fitFull(ef_obj)
  null_fitted <- fitNull(ef_obj)
  
  ## significance analysis
  #de_odp <- odp(ef_obj, bs.its = 50, verbose = FALSE, n.mods = 50)  # optimal discovery procedure (odp) doesn't work
  de_lrt <- lrt(de_obj, nullDistn = "normal")  # likelihood ratio test does work
  
  return(de_lrt)
}

timecourse.num <- c(0,6,12,26,52)  # timecourse values for the 0-100 scale
likert.time <- c(6,12,26,52)  # timecourse values for the likert scale

baseline.timecourse <- do.timecourse(all.df, baselinecols, timecourse.num)
sig_results <- qvalueObj(baseline.timecourse)

baselinepct.timecourse <- do.timecourse(all.df, baselinepctcols, timecourse.num)
baselikert.timecourse <- do.timecourse(all.df, baselinelikertcols, likert.time)


```
